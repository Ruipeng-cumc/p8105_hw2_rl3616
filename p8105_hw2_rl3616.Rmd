---
title: "Real-World Panel Data Cleaning"
author: "Ruipeng Li"
date: "Oct, 1, 2025"
output: github_document
---
Loading packages. 
```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(lubridate)      #to use parse_date_time
library(readxl)         #for problem 2
library(dplyr)          #filter
```

# FiveThirtyEight polls

#### Part 1
Clean the data in pols-month.csv.

```{r, message=FALSE, warning=FALSE}
pols_df <- read_csv("data/pols-month.csv") |>
  janitor::clean_names() |>
  separate(mon, into = c("year", "month", "day"), convert = TRUE) |>
  mutate(
    month = month.name[month],
    president = ifelse(prez_gop == 1, "gop", "dem")
    ) |>
  select(-prez_gop, -prez_dem, -day) |> 
  arrange(year, factor(month, levels = month.name))   #Old data to new data
```

Finished part one, let's looking at our new pols-month.

```{r}
pols_df
```

#### Part 2
clean the data in snp.csv
This is pretty complicate since we both have yyyy/m/d type of date and m/d/yy

```{r, message=FALSE, warning=FALSE}
snp_df <- read_csv("data/snp.csv") |>
  janitor::clean_names() |>
  mutate(date = parse_date_time(date, orders = c("ymd", "mdy"))) |>     #in this way I don't need to relocate()
  separate(date, into = c("year", "month", "day"), convert = TRUE) |>
  mutate(
    year  = if_else(year > 2015, year - 100L, year),
    month = month.name[month]
    ) |> 
  select(-day) |> 
  arrange(year, factor(month, levels = month.name))   #Old data to new data
```

I found "parse_date_time()" in lubridate package can both help me clean the "ymd" and "mdy" into "y-m-d" type, and arrange and organize the data, I don't know is that always happens? but I'm feeling complicate in using "skip" and something more like part one. 
```{r}
snp_df
```

#### Part 3
clean the data in unemployment.csv
```{r, message=FALSE, warning=FALSE}
unemp_df <- read_csv("data/unemployment.csv") |>
  janitor::clean_names() |>
  pivot_longer(
    cols = jan:dec,                 
    names_to = "month",
    values_to = "unemployment"
  ) |>
  mutate(
    month = month.name[match(month, tolower(month.abb))]       #Use tolower() to match the month in lowercase.
  ) |>
  arrange(year, factor(month, levels = month.name))   #Old data to new data
```


```{r}
unemp_df
```

#### Combaining all together

```{r}
final_df <- pols_df |>
  left_join(snp_df, by = c("year","month")) |>
  left_join(unemp_df, by = c("year","month"))
```

#### Conclusion
The ```pols-month``` table records the number of governors, senators, and representatives from each party during the presidential elections of different parties (Democratic/Republican).

The ```snp``` table represents stock market trends, and the ```close``` value reflects the overall stock price level of large companies.

The ```unemployment``` table represents the US unemployment rate.

We merged and then split the year and month data into the ```final_df``` table. This allows us to compare presidential party, stock market performance, and unemployment rates for a specific year and month, making it ideal for studying the relationship between politics, the economy, and employment.

The dataset spans 1947–2015 and covers many important historical events, such as the 1973–1975 oil crisis, the 1981–1982 recession, the 2000 dot-com bubble, and the 2007–2009 Great Recession. Therefore, this dataset provides significant reference value for studying the relationships between politics, the economy, and employment.

# Trash Wheels  
```{r}
path_trash <- "data/202509 Trash Wheel Collection Data.xlsx"

mr <- read_excel(path_trash, sheet = "Mr. Trash Wheel", skip=1, range = cell_cols("A:N"))
prof <- read_excel(path_trash, sheet = "Professor Trash Wheel", skip=1, range = cell_cols("A:M"))
gwyn <- read_excel(path_trash, sheet = "Gwynns Falls Trash Wheel", skip=1, range = cell_cols("A:L"))

mr <- mr |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |> 
  mutate(
    wheel = "Mr. Trash Wheel",
    date = ymd(date), 
    year  = as.integer(year(date)),
    month = month.name[month(date)],                                           #in order to unify data
    sports_balls = as.integer(round(sports_balls, 0))
    ) 

prof <- prof |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |> 
  mutate(
    wheel = "Professor Trash Wheel",
    date = ymd(date),
    year  = as.integer(year(date)),
    month = month.name[month(date)],                                           #in order to unify data
    ) 

gwyn <- gwyn |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |> 
  mutate(
    wheel = "Gwynns Falls Trash Wheel",
    date = ymd(date),
    year  = as.integer(year(date)),
    month = month.name[month(date)],                                           #in order to unify data
    ) 

final_wheels <- bind_rows(mr, prof, gwyn) |>
  arrange(date) |> 
  relocate("wheel","dumpster")

```

I successfully cleaned and combined the datasets for Mr. Trash Wheel, Professor Trash Wheel, and Gwynnda, resulting in a dataset containing `r nrow(final_wheels)` observations, with each row corresponding to a dumpster collection event.

(I didn't delete the `day` column as in Problem 1, as the event records are daily. I retained the full `date` column for better visualization. I also debated whether to delete the original `year` and `month`, but for statistical convenience, I retained them.) 

Key variables include the collection `date`, the `weight_tons` of trash collected,
the number of `cigarette_butts`, `plastic_bottles`, and `sports_balls` (rounded to integers),
as well as the estimated number of `homes_powered`.

```{r}
prof_total_weight <- final_wheels |>
  filter(wheel == "Professor Trash Wheel") |>
  summarise(total_weight = sum(weight_tons, na.rm = TRUE)) |>
  pull(total_weight)

gwyn_jun2022_cigs <- final_wheels |>
  filter(wheel == "Gwynns Falls Trash Wheel", year == 2022, month == "June") |> 
  summarise(total_cigrette_butts = sum(cigarette_butts, na.rm = TRUE)) |> 
  pull(total_cigrette_butts)
```
Across all available data, Professor Trash Wheel collected a total of `r round(prof_total_weight, 1)` tons of trash. In June 2022, Gwynnda collected `r format(gwyn_jun2022_cigs, big.mark = ",")` cigarette butts.

# Zillow ZORI  
```{r, message=FALSE, warning=FALSE}
zip_zori_df <- read_csv("data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv") |> 
  janitor::clean_names() |>
  rename(zip_code = region_name) |> 
  select(-region_type, -state_name, -state, -city, -metro) |> 
  pivot_longer(
    cols = starts_with("x20"),
    names_to = "date",
    values_to = "rent_price"
  ) |> 
  filter(!is.na(rent_price)) |>
  mutate(
    county_name = str_replace(county_name, " County", ""),
    date = str_replace(date, "x", ""),
    date = ymd(date)
    )
```

I deleted all the `region_type`, `state_name`, `state`, `city`, and `metro` column since they are with same variable useless in comparing two datasets. 

```{r, message=FALSE, warning=FALSE}
zip_codes_df <- read_csv("data/Zip Codes.csv") |> 
  janitor::clean_names() |>
  rename(county_name = county) |> 
  select(-state_fips, -county_code, -file_date)
```

Similar before, I deleted all the `state_fips`, `county_code` column since they are shows in `county_fips`, and deleted `file_date` column since they are with same variable useless in comparing two datasets. 

```{r}
new_york_zori <- zip_zori_df |>
  left_join(zip_codes_df, by = c("county_name","zip_code")) |> 
  relocate("region_id", "county_name", "county_fips", "zip_code")
```

We successfully combine the two tables and put the important information first, now step into Completeness & Correctness.

```{r}
# 1) check if any zip_code, date has duplicated
dup <- new_york_zori |> 
  count(zip_code, date) |> 
  filter(n > 1)
stopifnot(nrow(dup) == 0)

# 2) check the date and rent to be appropriate  and non-negative
summary_dates <- new_york_zori |>  
  summarise(
    any_neg = any(rent_price < 0, na.rm = TRUE),
    min_date = min(date, na.rm = TRUE),
    max_date = max(date, na.rm = TRUE),
    months   = n_distinct(date)
  )

min_date <- summary_dates$min_date
max_date <- summary_dates$max_date
months <- summary_dates$months
```
As we can see, there's no duplicated, inappropriate date and price, date started at `r min_date` and end at `r max_date`. Using calculation `2024-2015` we got `r 2024-2015` month, add `8` month from `2024`, we have `r (2024-2015)*12 + 8` month, which was same as `r months` month we got by `n_distinct()`.

In this dataset, we have `r nrow(new_york_zori)` rows, `r n_distinct(new_york_zori$zip_code)` different zip code, and `r n_distinct(new_york_zori$neighborhood, na.rm = TRUE)` different neighborhood.

```{r}
#Checking Zip codes
zips_in_zori <- zip_zori_df |> 
  distinct(zip_code)

zips_disappear <- zip_codes_df |> 
  anti_join(zips_in_zori, by = "zip_code")

zips_disappear
```

From the chart, we can see that most of these addresses do not point to neighborhoods (which neighborhoods is NA). Take the ZIP code 10499 as an example, which appears in the ZIP metadata but not in the Zillow dataset. This ZIP is a USPS-assigned unique code for postal facilities in the Bronx, rather than a residential neighborhood. Because such ZIP codes correspond to government or commercial facilities rather than housing markets, they are excluded from Zillow’s rental index. Some ZIP codes with community names (such as 10464) do not appear in Zillow’s listings, perhaps because they have a small population or users do not accept rentals.

```{r}
# filter data between January 2020 to 2021

jan2020_df <- new_york_zori |> 
  filter(year(date) == 2020, month(date) == 1) |> 
  select(zip_code, county_name, neighborhood, rent_2020 = rent_price)
  
jan2021_df <- new_york_zori |> 
  filter(year(date) == 2021, month(date) == 1) |> 
  select(zip_code, county_name, neighborhood, rent_2021 = rent_price)

# Merge and compare data

covid_comp_df <- jan2020_df |> 
  left_join(jan2021_df, by = c("zip_code", "county_name", "neighborhood")) |> 
  mutate(drop = rent_2021 - rent_2020) |> 
  arrange(drop) |> 
  slice(1:10)
  
```

Here's the table that shows the 10 ZIP codes (along with the borough and neighborhood) with largest drop in price from January 2020 to 2021.

```{r}
knitr::kable(covid_comp_df)
```

As we can see, rents in Lower Manhattan (ZIP 10007) showed the largest decline, dropping by about `r round(abs(covid_comp_df$drop[1]), 0)` dollars per month from January 2020 to January 2021. Other substantial declines also occurred in densely populated Manhattan neighborhoods, where high turnover and a reliance on rental apartments amplified the effects of the pandemic. This pattern is consistent with remote work policies and outmigration during COVID-19, which sharply reduced demand for central-city housing.

```{r}
write_csv(final_df, "FiveThirtyEight political polls & Unemployment.csv")
write_csv(final_wheels, "Wheels dumpster by time 2014-2025.csv")
write_csv(new_york_zori, "NYC Zori panel dataset.csv")
```